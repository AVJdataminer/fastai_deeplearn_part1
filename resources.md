# Resources

## Lessons

* [Lesson 2: Case Study - A world class image classifier for dogs and cats (err.., anything)](https://medium.com/@apiltamang/case-study-a-world-class-image-classifier-for-dogs-and-cats-err-anything-9cf39ee4690e) by Apil Tamang

* [Lesson 2 Notes](http://forums.fast.ai/t/deeplearning-lecnotes2/7515/2) by Tim Lee


## Blogs Written by fastai Fellows

### Resnet
* [Decoding the ResNet architecture](http://teleported.in/posts/decoding-resnet-architecture/) by Anand Saha   
* [Yet Another ResNet Tutorial (or not)]https://medium.com/@apiltamang/yet-another-resnet-tutorial-or-not-f6dd9515fcd7) by Apil Tamang

### PyTorch
* [Transfer Learning using PyTorch — Part 2](https://towardsdatascience.com/transfer-learning-using-pytorch-part-2-9c5b18e15551) by Vishnu Subramanian (April 2017)
* [A practitioner's guide to PyTorch](https://medium.com/@radekosmulski/a-practitioners-guide-to-pytorch-1d0f6a238040) by Radek 

### Learning Rate
* [Visualizing Learning rate vs Batch size (Neural Nets basics using Fast.ai tools)](https://miguel-data-sc.github.io/2017-11-05-first/) by Miguel (Nov 2017)
* [Estimating an Optimal Learning Rate For a Deep Neural Network](https://medium.com/@surmenok/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0) by Pavel Surmenok

### and More
* [Do smoother areas of the error surface lead to better generalization?](https://medium.com/@radekosmulski/do-smoother-areas-of-the-error-surface-lead-to-better-generalization-b5f93b9edf5b) by Radek
  * An experiment inspired by the first lecture of the fast.ai MOOC

* [Contributing to fast.ai](https://medium.com/@wgilliam/86f2c05d72aa) by Wayde Gilliam

* [Convolutional Neural Network in 5 minutes](https://medium.com/@init_27/convolutional-neural-network-in-5-minutes-8f867eb9ca39) by Sanyam Bhutani


## Blogs

* [Debugging Jupyter notebooks](https://davidhamann.de/2017/04/22/debugging-jupyter-notebooks/)

* [An Overview of ResNet and its Variants](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035)


## Publications

* [What’s your ML Test Score? A rubric for ML
production systems](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45742.pdf)  (NIPS 2016)  

* [ADAM:  A Method for Stochastic Optimization](https://arxiv.org/pdf/1412.6980.pdf) (ICLR 2015)

* [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186) (WACV 2017)


## Videos

* [The wonderful and terrifying implications of computers that can learn](https://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn) (Ted Talk by Jeremy Howard 2014)

* [Ian Goodfellow - Numerical Computation for Deep Learning - AI With The Best Oct 14-15, 2017](https://www.youtube.com/watch?v=XlYD8jn1ayE&t=5m40s)

## To Explore Later

[byobu](http://byobu.co) Byobu is a GPLv3 open source text-based window manager and terminal multiplexer.
