# Lesson 7  
live 11-Dec-2017

[Video: Lesson 7](https://www.youtube.com/watch?v=H3g26EVADgY&feature=youtu.be)

[Wiki: Lesson 7](http://forums.fast.ai/t/lesson-7-wiki-thread/8847/1)

Notebooks:  
* [lesson5-movielens.ipynb](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb)
* [lesson6-rnn.ipynb](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-rnn.ipynb)
* [lesson3-rossman.ipynb](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb)
* [lesson6-sgd.ipynb[(https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-sgd.ipynb) 

## Blogs to Review

## Other links
- WILD ML RNN Tutorial - http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/
- Chris Olah on LSTM http://colah.github.io/posts/2015-08-Understanding-LSTMs/
- More from Olah and others - https://distill.pub/
- [BatchNorm paper](https://arxiv.org/pdf/1502.03167.pdf)
- [Laptop recommendation](https://youtu.be/EKzSiuqiHNg?t=1h1m51s); [Surface Book 2 15 inch](https://www.cnet.com/products/microsoft-surface-book-2/review/)


## Theme of Part 1
- classification and regression with deep learning
- identifying best practices
- here are 3 lines of code for image classification
- first 4 lessons were NLP, structured data, collaborative filtering
- last 3 lessons were above topics in more detail, more detailed code

## Theme of Part 2
- generative modeling
- creating a sentence, image captioning, neural translation
- creating an image, style transfer
- moving from best practices to speculative practices
- how to read a paper and implement from scratch
- does not assume a particular math background, but be prepared to dig through notation and convert to code

## RNN
- not so different
- they are like a fully connected network

## Batch Size
`bs=64` means data is split into 65 chunks of data.  
NOT batches of size 64!  

## Data Augmentation for NLP
- JH can't talk about that; doesn't know a good way
- JH will do further study on that



